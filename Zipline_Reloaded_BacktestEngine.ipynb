{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Zipline_Reloaded_BacktestEngine.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/helmieresearch/helmieresearch/blob/main/Zipline_Reloaded_BacktestEngine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß∞**INSTALL MODULES**"
      ],
      "metadata": {
        "id": "xRTs1_SK0Scj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ABrWrt1q06gq",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tlwk44QhErd"
      },
      "source": [
        "# Install ta-lib v0.4.0\n",
        "%%bash\n",
        "wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
        "tar -xzf ta-lib-0.4.0-src.tar.gz\n",
        "cd ta-lib/\n",
        "./configure\n",
        "make\n",
        "make install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSwN3Ywihz3r",
        "collapsed": true
      },
      "source": [
        "# Install zipline\n",
        "%pip install zipline-reloaded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install iso3166==2.0.2"
      ],
      "metadata": {
        "id": "w2cgjqTU8TKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Pyfolio\n",
        "!pip install pyfolio-reloaded"
      ],
      "metadata": {
        "id": "m-y07xfPTFVK",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install matplot library\n",
        "!pip install matplotlib"
      ],
      "metadata": {
        "collapsed": true,
        "id": "zoV1_FSc_5MW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install data bundle 'Quandl'\n",
        "!pip install quandl"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8-pgTCGp2XzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipline\n",
        "zipline.__version__"
      ],
      "metadata": {
        "id": "C9erwAEdVunF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nasdaq-data-link"
      ],
      "metadata": {
        "id": "jjqASrBOT4Rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üíΩ**SET WORKING DIRECTORY**"
      ],
      "metadata": {
        "id": "4Ixua2eyz0Hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "\n",
        "# Set your working directory to a folder in your Google Drive. This way, if your notebook times out,\n",
        "# your files will be saved in your Google Drive!\n",
        "\n",
        "# the base Google Drive directory\n",
        "root_dir = \"/content/drive/\"\n"
      ],
      "metadata": {
        "id": "eWtZZXQol34j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "\n",
        "# Set your working directory to a folder in your Google Drive. This way, if your notebook times out,\n",
        "# your files will be saved in your Google Drive!\n",
        "\n",
        "\n",
        "# choose where you want your project files to be saved\n",
        "project_folder = \"MyDrive/Colab Notebooks/My Project Folder\"\n"
      ],
      "metadata": {
        "id": "c4jxNssSmApK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_and_set_working_directory(project_folder):\n",
        "  # check if your project folder exists. if not, it will be created.\n",
        "  if os.path.isdir(root_dir + project_folder) == False:\n",
        "    os.mkdir(root_dir + project_folder)\n",
        "    print(root_dir + project_folder + ' did not exist but was created.')\n",
        "\n",
        "  # change the OS to use your project folder as the working directory\n",
        "  os.chdir(root_dir + project_folder)\n",
        "\n",
        "  # create a test file to make sure it shows up in the right place\n",
        "  !touch 'new_file_in_working_directory.txt'\n",
        "  print('\\nYour working directory was changed to ' + root_dir + project_folder + \\\n",
        "        \"\\n\\nAn empty text file was created there. You can also run !pwd to confirm the current working directory.\" )\n",
        "\n",
        "create_and_set_working_directory(project_folder)"
      ],
      "metadata": {
        "id": "Y0PGKB_SmAR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm current working directory\n",
        "!pwd"
      ],
      "metadata": {
        "id": "Q4_HSs4HneUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for f in os.listdir(\"//content/drive/MyDrive/Colab Notebooks/My Project Folder\"):\n",
        "\tprint(f)"
      ],
      "metadata": {
        "id": "8HB8gDZGqsfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚è≥**INGEST DATA**"
      ],
      "metadata": {
        "id": "z5Y1KYNHeqeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ingest custom bundle\n",
        "!zipline ingest --bundle 'crypto'"
      ],
      "metadata": {
        "id": "CvMaJ1U1eVhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ingest custom bundle\n",
        "!zipline ingest --bundle 'equities_csvdir'"
      ],
      "metadata": {
        "id": "okd6vU6j5iPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ingest custom bundle\n",
        "!zipline ingest --bundle 'random_futures_data'"
      ],
      "metadata": {
        "id": "1tKhQWGK5Z8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ingest custom bundle\n",
        "!zipline ingest --bundle 'random_stock_data'"
      ],
      "metadata": {
        "id": "lvSZVAHNJDW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "INGEST QUANDL STOCK BUNDLE\n",
        "'''\n",
        "# Ingest bundle API\n",
        "!QUANDL_API_KEY=KUnssHvVERHb5XYu9C1- zipline ingest -b 'quandl'"
      ],
      "metadata": {
        "id": "KiUF_IBQCSlm",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm existing bundles\n",
        "!zipline bundles"
      ],
      "metadata": {
        "id": "Ol2e01cH_O3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean everything older than <date>\n",
        "!zipline clean -b crypto --after 2022-04-13"
      ],
      "metadata": {
        "id": "mzYjOy4meAx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìä**ANDREAS CLENOW MODELS**"
      ],
      "metadata": {
        "id": "r6pHOCkwUJOo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Clenow Momentum Model**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "EHQUpvbK0RNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "%matplotlib inline\n",
        "\n",
        "import zipline\n",
        "from zipline import run_algorithm\n",
        "from zipline.api import order_target_percent, symbol, set_commission, set_slippage, schedule_function, date_rules, time_rules\n",
        "from pandas import Timestamp\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "import matplotlib.pyplot as plt \n",
        "import pyfolio as pf\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "from scipy import stats\n",
        "from zipline.finance.commission import PerDollar\n",
        "from zipline.finance.slippage import VolumeShareSlippage, FixedSlippage\n",
        "\n",
        "#Model Settings\n",
        "\n",
        "intial_portfolio = 100000\n",
        "momentum_window = 125\n",
        "minimum_momentum = 40\n",
        "portfolio_size = 30\n",
        "vola_window = 20\n",
        "\n",
        "#Commission and Slippage Settings\n",
        "\n",
        "enable_commission = True \n",
        "commission_pct = 0.001 \n",
        "enable_slippage = True \n",
        "slippage_volume_limit = 0.025\n",
        "slippage_impact = 0.05\n",
        "\n",
        "def momentum_score(ts):\n",
        "\n",
        "  #Input: Price time series.Output: Annualized exponential regression slope, multiplied by the R2\n",
        "\n",
        "  # Make a list of consecutive numbers \n",
        "  x = np.arange(len(ts))\n",
        "  # Get logs\n",
        "  log_ts = np.log(ts)\n",
        "  # Calculate regression values\n",
        "  slope, intercept, r_value, p_value, std_err = stats.linregress(x, log_ts) \n",
        "  # Annualize percent\n",
        "  annualized_slope = (np.power(np.exp(slope), 252) - 1) * 100 \n",
        "  #Adjust for fitness\n",
        "  score = annualized_slope * (r_value ** 2) \n",
        "  return score\n",
        "\n",
        "def volatility(ts):\n",
        "  return ts.pct_change().rolling(vola_window).std().iloc[-1]\n",
        "\n",
        "def output_progress(context):\n",
        "\n",
        "  #Output some performance numbers during backtest run \n",
        "  #This code just prints out the past month's performance,\n",
        "  # so that we have something to look at while the backtest runs.\n",
        "\n",
        "  # Get today's date\n",
        "  today = zipline.api.get_datetime().date()\n",
        "\n",
        "  # Calculate percent difference since last month\n",
        "  perf_pct = (context.portfolio.portfolio_value / context.last_month) - 1\n",
        "\n",
        "  # Print performance, format as percent with two decimals. \n",
        "  print(\"{} - Last Month Result: {:.2%}\".format(today, perf_pct))\n",
        "\n",
        "  # Remember today's portfolio value for next month's calculation \n",
        "  context.last_month = context.portfolio.portfolio_value\n",
        "\n",
        "#Initialization and trading logic\n",
        "\n",
        "\n",
        "def initialize(context):\n",
        "\n",
        "  # Set commission and slippage.\n",
        "  if enable_commission:\n",
        "    comm_model = PerDollar(cost=commission_pct) \n",
        "  else:\n",
        "    comm_model = PerDollar(cost=0.0) \n",
        "  set_commission(comm_model)\n",
        "  if enable_slippage: slippage_model=VolumeShareSlippage(volume_limit=slippage_volume_limit,\n",
        "price_impact=slippage_impact) \n",
        "  else:\n",
        "    slippage_model=FixedSlippage(spread=0.0) \n",
        "  set_slippage(slippage_model)\n",
        "\n",
        "  # Used only for progress output. \n",
        "  context.last_month = intial_portfolio\n",
        "\n",
        "  # Store index membership\n",
        "  context.index_members = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/index members/sp500.csv', engine='python', error_bad_lines=False)\n",
        "\n",
        "\n",
        "  #Schedule rebalance monthly. \n",
        "  schedule_function(\n",
        "    func=rebalance, \n",
        "    date_rule=date_rules.month_start(), \n",
        "    time_rule=time_rules.market_open()\n",
        "  )\n",
        "\n",
        "def rebalance(context, data):\n",
        "  # Write some progress output during the backtest \n",
        "  output_progress(context)\n",
        "\n",
        "  # First, get today's date\n",
        "  today = zipline.api.get_datetime().date()\n",
        "\n",
        "  # Second, get the index makeup for all days prior to today.\n",
        "  all_prior = context.index_members.loc[context.index_members.index < today]\n",
        "\n",
        "  todays_universe = [ \n",
        "    symbol(ticker) for ticker in\n",
        "    context.index_members.loc[context.index_members.index < today].iloc[-1,0].split(',')\n",
        "  ]\n",
        "\n",
        "  # Get historical data\n",
        "  hist = data.history(todays_universe, \"close\", momentum_window, \"1d\")\n",
        "\n",
        "  # Make momentum ranking table\n",
        "  ranking_table = hist.apply(momentum_score).sort_values(ascending=False)\n",
        "\n",
        "  #Sell Logic\n",
        "  #First we check if any existing position should be sold.\n",
        "    #Sell if stock is no longer part of index.\n",
        "    #Sell if stock has too low momentum value.\n",
        "\n",
        "  kept_positions = list(context.portfolio.positions.keys()) \n",
        "  for security in context.portfolio.positions:\n",
        "    if (security not in todays_universe): \n",
        "      order_target_percent(security, 0.0) \n",
        "      kept_positions.remove(security)\n",
        "    elif ranking_table[security] < minimum_momentum: \n",
        "      order_target_percent(security, 0.0) \n",
        "      kept_positions.remove(security)\n",
        "\n",
        "  #Stock Selection Logic\n",
        "  #Check how many stocks we are keeping from last month.\n",
        "  #Fill from top of ranking list, until we reach the desired total number of portfolio holdings.\n",
        "\n",
        "  replacement_stocks = portfolio_size - len(kept_positions) \n",
        "  buy_list = ranking_table.loc[\n",
        "    ~ranking_table.index.isin(kept_positions)][:replacement_stocks]\n",
        "  new_portfolio = pd.concat(\n",
        "    (buy_list,\n",
        "    ranking_table.loc[ranking_table.index.isin(kept_positions)])\n",
        "  )\n",
        "  buy_list = ranking_table.loc[\n",
        "    ~ranking_table.index.isin(kept_positions)][:replacement_stocks]\n",
        "\n",
        "  #Calculate inverse volatility for stocks, and make target position weights.\n",
        "\n",
        "  vola_table = hist[new_portfolio.index].apply(volatility) \n",
        "  inv_vola_table = 1 / vola_table\n",
        "  sum_inv_vola = np.sum(inv_vola_table) \n",
        "  vola_target_weights = inv_vola_table / sum_inv_vola\n",
        "  for security, rank in new_portfolio.iteritems(): \n",
        "    weight = vola_target_weights[security]\n",
        "    if security in kept_positions:\n",
        "      order_target_percent(security, weight)\n",
        "    else:\n",
        "      if ranking_table[security] > minimum_momentum: \n",
        "        order_target_percent(security, weight)\n",
        "\n",
        "def analyze(context, perf):\n",
        "  perf['max'] = perf.portfolio_value.cummax() \n",
        "  perf['dd'] = (perf.portfolio_value / perf['max']) - 1 \n",
        "  maxdd = perf['dd'].min()\n",
        "\n",
        "  ann_ret = (np.power((perf.portfolio_value.iloc[-1] / perf.portfolio_value.iloc[0]),(252 / len(perf)))) - 1\n",
        "\n",
        "  print(\"Annualized Return: {:.2%} Max Drawdown: {:.2%}\".format(ann_ret, maxdd))\n",
        "\n",
        "  return\n",
        "'''\n",
        "start = datetime(1997, 1, 1, 8, 15, 12, 0, pytz.UTC)\n",
        "end = datetime(2018, 12, 31, 8, 15, 12, 0, pytz.UTC)\n",
        "'''\n",
        "\n",
        "start = pd.Timestamp('1997-1-1', tz='utc')\n",
        "end = pd.Timestamp('2018-12-31', tz='utc')\n",
        "\n",
        "perf = zipline.run_algorithm(start=start, end=end, \n",
        "                             initialize=initialize, \n",
        "                             analyze=analyze, \n",
        "                             capital_base=intial_portfolio, \n",
        "                             data_frequency = 'daily', \n",
        "                             bundle='quandl' )"
      ],
      "metadata": {
        "id": "6aRGAkzKLH88",
        "collapsed": true,
        "cellView": "code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Clenow Trend Model**"
      ],
      "metadata": {
        "id": "x83jcz1QUFDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import zipline\n",
        "from zipline.api import future_symbol,  \\\n",
        "    set_commission, set_slippage, schedule_function, date_rules, \\\n",
        "    time_rules, continuous_future, order_target\n",
        "from pandas import Timestamp\n",
        "import pytz\n",
        "import datetime as datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import pyfolio as pf\n",
        "import pandas as pd\n",
        "import numpy as np  \n",
        "from zipline.finance.commission import PerTrade, PerContract\n",
        "from zipline.finance.slippage import VolumeShareSlippage, \\\n",
        "    FixedSlippage, VolatilityVolumeShare\n",
        "\n",
        "# These lines are for the dynamic text reporting\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "out = widgets.HTML()\n",
        "display(out)\n",
        "\n",
        "\"\"\"\n",
        "Model Settings\n",
        "\"\"\"\n",
        "starting_portfolio = 50000000\n",
        "risk_factor = 0.0015\n",
        "stop_distance = 3\n",
        "breakout_window = 50\n",
        "vola_window = 40\n",
        "slow_ma = 80\n",
        "fast_ma = 40\n",
        "enable_commission = True\n",
        "enable_slippage = True  \n",
        "\n",
        "\n",
        "def report_result(context, data):\n",
        "    context.months += 1\n",
        "    today = zipline.api.get_datetime().date()\n",
        "    # Calculate annualized return so far\n",
        "    ann_ret = np.power(context.portfolio.portfolio_value / starting_portfolio, \n",
        "                   12 / context.months) - 1\n",
        "    \n",
        "    # Update the text\n",
        "    out.value = \"\"\"{} We have traded <b>{}</b> months \n",
        "    and the annualized return is <b>{:.2%}</b>\"\"\".format(today, context.months, ann_ret)\n",
        "\n",
        "def roll_futures(context, data):\n",
        "    open_orders = zipline.api.get_open_orders()\n",
        "    \n",
        "    for held_contract in context.portfolio.positions:\n",
        "        # don't roll positions that are set to change by core logic\n",
        "        if held_contract in open_orders: \n",
        "            continue\n",
        "        \n",
        "        # Save some time by only checking rolls for\n",
        "        # contracts stopping trading in the next days\n",
        "        days_to_auto_close = (\n",
        "            held_contract.auto_close_date.date() - data.current_session.date()\n",
        "        ).days\n",
        "        if days_to_auto_close > 5:\n",
        "            continue        \n",
        "        \n",
        "        # Make a continuation\n",
        "        continuation = continuous_future(\n",
        "                held_contract.root_symbol, \n",
        "                offset=0, \n",
        "                roll='volume', \n",
        "                adjustment='mul'\n",
        "                )\n",
        "        \n",
        "        # Get the current contract of the continuation\n",
        "        continuation_contract = data.current(continuation, 'contract')\n",
        "        \n",
        "        if continuation_contract != held_contract:\n",
        "            # Check how many contracts we hold\n",
        "            pos_size = context.portfolio.positions[held_contract].amount         \n",
        "            # Close current position\n",
        "            order_target(held_contract, 0)\n",
        "            # Open new position\n",
        "            order_target(continuation_contract, pos_size)     \n",
        "            \n",
        "def position_size(portfolio_value, std, point_value):\n",
        "    target_variation = portfolio_value * risk_factor\n",
        "    contract_variation = std * point_value\n",
        "    contracts = target_variation / contract_variation\n",
        "    return int(np.nan_to_num(contracts)) \n",
        "    \n",
        "def initialize(context):\n",
        "    \n",
        "    \"\"\"\n",
        "    Cost Settings\n",
        "    \"\"\"\n",
        "    if enable_commission:\n",
        "        comm_model = PerContract(cost=0.85, exchange_fee=1.5)\n",
        "    else:\n",
        "        comm_model = PerTrade(cost=0.0)\n",
        "        \n",
        "    set_commission(us_futures=comm_model)\n",
        "    \n",
        "    if enable_slippage:\n",
        "        slippage_model=VolatilityVolumeShare(volume_limit=0.2)\n",
        "    else:\n",
        "        slippage_model=FixedSlippage(spread=0.0)      \n",
        "        \n",
        "    set_slippage(us_futures=slippage_model)\n",
        "    \n",
        "    \"\"\"\n",
        "    Markets to trade\n",
        "    \"\"\" \n",
        "    currencies = [\n",
        "        'AD',\n",
        "        'BP',\n",
        "        'CD',\n",
        "        'CU',\n",
        "        'DX',\n",
        "        'JY',\n",
        "        'NE',\n",
        "        'SF',\n",
        "    ]\n",
        "    \n",
        "    agricultural = [\n",
        "        '_C',\n",
        "        'CT',\n",
        "        'FC',\n",
        "        'KC',\n",
        "        'LR',\n",
        "        'LS',\n",
        "        '_O',\n",
        "        '_S',\n",
        "        'SB',\n",
        "        'SM',\n",
        "        '_W',\n",
        "    ]\n",
        "    nonagricultural = [\n",
        "        'CL',\n",
        "        'GC',\n",
        "        'HG',\n",
        "        'HO',\n",
        "        'LG',\n",
        "        'NG',\n",
        "        'PA',\n",
        "        'PL',\n",
        "        'RB',\n",
        "        'SI',\n",
        "    ]\n",
        "    equities = [\n",
        "        'ES',\n",
        "        'NK',\n",
        "        'NQ',\n",
        "        'TW',\n",
        "        'VX',\n",
        "        'YM',\n",
        "    ]\n",
        "    rates = [\n",
        "        'ED',\n",
        "        'FV',\n",
        "        'TU',\n",
        "        'TY',\n",
        "        'US',\n",
        "    ]\n",
        "    \n",
        "    # Make a list of all the markets\n",
        "    markets = currencies + agricultural + nonagricultural + equities + rates\n",
        "    \n",
        "    # Make a list of all continuations\n",
        "    context.universe = [\n",
        "        continuous_future(market, offset=0, roll='volume', adjustment='mul')\n",
        "            for market in markets\n",
        "    ]\n",
        "    \n",
        "    # We'll use these to keep track of best position reading\n",
        "    # Used to calculate stop points.\n",
        "    context.highest_in_position = {market: 0 for market in markets} \n",
        "    context.lowest_in_position = {market: 0 for market in markets}    \n",
        "    \n",
        "    # Schedule the daily trading\n",
        "    schedule_function(daily_trade, date_rules.every_day(), time_rules.market_close())\n",
        "    \n",
        "    # We'll just use this for the progress output\n",
        "    # during the backtest. Doesn't impact anything.\n",
        "    context.months = 0    \n",
        "    \n",
        "    # Schedule monthly report output\n",
        "    schedule_function(\n",
        "        func=report_result,\n",
        "        date_rule=date_rules.month_start(),\n",
        "        time_rule=time_rules.market_open()\n",
        "    ) \n",
        "    \n",
        "def analyze(context, perf):\n",
        "    returns, positions, transactions = pf.utils.extract_rets_pos_txn_from_zipline(perf)\n",
        "    pf.create_returns_tear_sheet(returns, benchmark_rets=None)\n",
        "    \n",
        "def daily_trade(context, data):\n",
        "    # Get continuation data\n",
        "    hist = data.history(\n",
        "        context.universe, \n",
        "        fields=['close','volume'], \n",
        "        frequency='1d', \n",
        "        bar_count=250,\n",
        "    )\n",
        "    \n",
        "    # Calculate trend\n",
        "    hist['trend'] = hist['close'].ewm(span=fast_ma).mean() > hist['close'].ewm(span=slow_ma).mean()    \n",
        "    \n",
        "    # Make dictionary of open positions\n",
        "    open_pos = {\n",
        "        pos.root_symbol: pos \n",
        "        for pos in context.portfolio.positions\n",
        "    } \n",
        "    \n",
        "    # Iterate markets, check for trades\n",
        "    for continuation in context.universe:\n",
        "        \n",
        "        # Get root symbol of continuation\n",
        "        root = continuation.root_symbol\n",
        "        \n",
        "        # Slice off history for just this market\n",
        "        h = hist.xs(continuation, 2)\n",
        "        \n",
        "        # Get standard deviation\n",
        "        std = h.close.diff()[-vola_window:].std()\n",
        "\n",
        "        if root in open_pos: # Position is open\n",
        "\n",
        "            # Get position\n",
        "            p = context.portfolio.positions[open_pos[root]]\n",
        "            \n",
        "            if p.amount > 0: # Position is long\n",
        "                if context.highest_in_position[root] == 0: # First day holding the position\n",
        "                    context.highest_in_position[root] = p.cost_basis\n",
        "                else:\n",
        "                    context.highest_in_position[root] = max(\n",
        "                        h['close'].iloc[-1], context.highest_in_position[root]\n",
        "                    ) \n",
        "                    \n",
        "                # Calculate stop point\n",
        "                stop = context.highest_in_position[root] - (std  * stop_distance)\n",
        "                # Check if stop is hit\n",
        "                if h.iloc[-1]['close'] < stop:\n",
        "                    contract = open_pos[root]\n",
        "                    order_target(contract, 0)\n",
        "                    context.highest_in_position[root] = 0\n",
        "                # Check if trend has flipped\n",
        "                elif h['trend'].iloc[-1] == False:\n",
        "                    contract = open_pos[root]\n",
        "                    order_target(contract, 0)\n",
        "                    context.highest_in_position[root] = 0\n",
        "                    \n",
        "            else: # Position is short\n",
        "                if context.lowest_in_position[root] == 0: # First day holding the position\n",
        "                    context.lowest_in_position[root] = p.cost_basis\n",
        "                else:\n",
        "                    context.lowest_in_position[root] = min(\n",
        "                        h['close'].iloc[-1], context.lowest_in_position[root]\n",
        "                    )\n",
        "                \n",
        "                # Calculate stop point\n",
        "                stop = context.lowest_in_position[root] + (std  * stop_distance)\n",
        "                \n",
        "                # Check if stop is hit\n",
        "                if h.iloc[-1]['close'] > stop:\n",
        "                    contract = open_pos[root]\n",
        "                    order_target(contract, 0)\n",
        "                    context.lowest_in_position[root] = 0\n",
        "                # Check if trend has flipped\n",
        "                elif h['trend'].iloc[-1] == True:\n",
        "                    contract = open_pos[root]\n",
        "                    order_target(contract, 0)\n",
        "                    context.lowest_in_position[root] = 0                         \n",
        "        \n",
        "        else: # No position on\n",
        "            if h['trend'].iloc[-1]: # Bull trend\n",
        "                # Check if we just made a new high\n",
        "                if h['close'][-1] == h[-breakout_window:]['close'].max(): \n",
        "                    contract = data.current(continuation, 'contract')\n",
        "\n",
        "                    contracts_to_trade = position_size( \\\n",
        "                                                       context.portfolio.portfolio_value, \\\n",
        "                                                       std, \\\n",
        "                                                       contract.price_multiplier)\n",
        "                    \n",
        "                    # Limit size to 20% of avg. daily volume\n",
        "                    contracts_cap = int(h['volume'][-20:].mean() * 0.2)\n",
        "                    contracts_to_trade = min(contracts_to_trade, contracts_cap)\n",
        "                    \n",
        "                    # Place the order\n",
        "                    order_target(contract, contracts_to_trade)\n",
        "             \n",
        "            else: # Bear trend\n",
        "                # Check if we just made a new low\n",
        "                if h['close'][-1] == h[-breakout_window:]['close'].min(): \n",
        "                    contract = data.current(continuation, 'contract')\n",
        "\n",
        "                    contracts_to_trade = position_size( \\\n",
        "                                                       context.portfolio.portfolio_value, \\\n",
        "                                                       std, \\\n",
        "                                                       contract.price_multiplier)\n",
        "                    \n",
        "                    # Limit size to 20% of avg. daily volume\n",
        "                    contracts_cap = int(h['volume'][-20:].mean() * 0.2)\n",
        "                    contracts_to_trade = min(contracts_to_trade, contracts_cap)\n",
        "                    \n",
        "                    # Place the order\n",
        "                    order_target(contract, -1 * contracts_to_trade)\n",
        "    \n",
        "    # If we have open positions, check for rolls\n",
        "    if len(open_pos) > 0:   \n",
        "        roll_futures(context, data)                \n",
        "                        \n",
        "\n",
        "start = pd.Timestamp('2003-01-01', tz='utc')\n",
        "end = pd.Timestamp('2017-12-31', tz='utc')\n",
        "\n",
        "perf = zipline.run_algorithm(\n",
        "    start=start, end=end, \n",
        "    initialize=initialize, \n",
        "    analyze=analyze,\n",
        "    capital_base=starting_portfolio,  \n",
        "    data_frequency = 'daily', \n",
        "    bundle='random_futures_data' ) \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sponWV8ZKDJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üíª**MODEL TESTING**"
      ],
      "metadata": {
        "id": "8gWXJGjGBDbs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**DIGITAL ASSETS PROGRAMME**\n",
        "\n"
      ],
      "metadata": {
        "id": "tIM7wTXOAarM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Systems**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "TycKaYmxuCVl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Single Asset Backtest"
      ],
      "metadata": {
        "id": "ySxEKidEU606"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This ensures that our graphs will be shown properly in the notebook.\n",
        "%matplotlib inline\n",
        "\n",
        "# Import libraries\n",
        "import zipline\n",
        "from zipline import run_algorithm\n",
        "from zipline.api import order_target_percent, symbol\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "def initialize(context):\n",
        "  # Which asset to trade\n",
        "  context.asset = symbol('btc')\n",
        "  \n",
        "  # Moving average window\n",
        "  context.index_average_window = 100\n",
        "\n",
        "def handle_data(context, data):\n",
        "  # Request history for the stock\n",
        "  btc_hist = data.history(context.asset, \"close\",\n",
        "                               context.index_average_window, \"1d\")\n",
        "  \n",
        "  # Check if price is above moving average\n",
        "  if btc_hist[-1] > btc_hist.mean():\n",
        "    asset_weight = 1.0\n",
        "  else:\n",
        "    asset_weight = 0.0\n",
        "    # Place order\n",
        "    order_target_percent(context.asset, asset_weight)\n",
        "\n",
        "def analyze(context, perf):\n",
        "  \n",
        "  fig = plt.figure(figsize=(12, 8))\n",
        "  \n",
        "    # First char\n",
        "  ax = fig.add_subplot(311)\n",
        "  ax.set_title('Strategy Results')\n",
        "  ax.semilogy(perf['portfolio_value'], linestyle='-',\n",
        "              label='Equity Curve', linewidth=3.0)\n",
        "  ax.legend()\n",
        "  ax.grid(False)\n",
        "\n",
        "  # Second chart\n",
        "  ax = fig.add_subplot(312)\n",
        "  ax.plot(perf['gross_leverage'],\n",
        "  label='Exposure', linestyle='-', linewidth=1.0)\n",
        "  ax.legend()\n",
        "  ax.grid(True)\n",
        "\n",
        "  # Third chart\n",
        "  ax = fig.add_subplot(313)\n",
        "  ax.plot(perf['returns'], label='Returns', linestyle='-.',\n",
        "          linewidth=1.0)"
      ],
      "metadata": {
        "id": "kcHu_Gsb7cll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Equal Weight Model"
      ],
      "metadata": {
        "id": "_tfGWw1gYDlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This ensures that our graphs will be shown properly in the notebook.\n",
        "%matplotlib inline\n",
        "\n",
        "# Import a few libraries we need\n",
        "from zipline import run_algorithm\n",
        "from zipline.api import order_target_percent, record, symbol, set_benchmark\n",
        "import pyfolio as pf\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def initialize(context):\n",
        "\n",
        "  # Which stock to trade\n",
        "\n",
        "  \"\"\"\n",
        "  dji = [\"JEC\",\"BBY\",\"MSFT\",\"MCHP\",\"PEP\",\n",
        "         \"RAD\",\"PTC\",\"GCO\",\"FAST\",\"CTL\",\n",
        "         \"APA\",\"EL\",\"TMK\",\"VVI\",\"HPQ\",\n",
        "         \"CMCSA\",\"JCI\",\"T\"]\n",
        "\n",
        "  dji = [\"aave\",\"ada\",\"algo\",\"alpha\",\"ant\",\n",
        "         \"bal\",\"bat\",\"bch\",\"bnb\",\"bsv\",\n",
        "         \"btc\"]\n",
        "  \"\"\"\n",
        "\n",
        "  dji = [\"btc\"]\n",
        "\n",
        "\n",
        "  # Make a list of symbols from the list of tickers\n",
        "  context.dji_symbols = [symbol(s) for s in dji]\n",
        "\n",
        "  # Moving average window\n",
        "  context.index_average_window = 52\n",
        "  \n",
        "def handle_data(context, data):\n",
        "  \n",
        "  # Get history for all the stocks\n",
        "  stock_hist = data.history(context.dji_symbols, \"close\", context.index_average_window, \"1d\")\n",
        "\n",
        "  # Make an empty DataFrame to start with\n",
        "  stock_analytics = pd.DataFrame()\n",
        "\n",
        "  # Add column for above or below average\n",
        "  stock_analytics['above_mean'] = stock_hist.iloc[-1] > stock_hist.mean()\n",
        "\n",
        "  # Set weight for stocks to buy\n",
        "  stock_analytics.loc[stock_analytics['above_mean'] == True, 'weight'] = 1/len(context.dji_symbols)\n",
        "\n",
        "  # Set weight to zero for the rest\n",
        "  stock_analytics.loc[stock_analytics['above_mean'] == False, 'weight'] = 0.0\n",
        "\n",
        "  # Iterate each row and place trades\n",
        "  for stock, analytics in stock_analytics.iterrows():\n",
        "\n",
        "    # Check if the stock can be traded\n",
        "    if data.can_trade(stock):\n",
        "\n",
        "      # Place the trade\n",
        "      order_target_percent(stock, analytics['weight'])\n",
        "\n",
        "def analyze(context, perf):\n",
        "\n",
        "  # Use PyFolio to generate a performance report\n",
        "  returns, positions, transactions = pf.utils.extract_rets_pos_txn_from_zipline(perf)\n",
        "\n",
        "  benchmark_period_return = perf['benchmark_period_return']\n",
        "\n",
        "  daily_benchmark_returns = np.exp(np.log(benchmark_period_return + 1.0).diff()) - 1\n",
        "\n",
        "  # Create tear sheet\n",
        "  pf.create_full_tear_sheet(returns, positions=positions, transactions=transactions, benchmark_rets=None)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def analyze(context, perf):\n",
        "\n",
        "  fig = plt.figure(figsize=(12, 8))\n",
        "\n",
        "  # First chart\n",
        "  ax = fig.add_subplot(311)\n",
        "  ax.set_title('Strategy Results')\n",
        "  ax.plot(perf['portfolio_value'], linestyle='-',\n",
        "          label='Equity Curve', linewidth=3.0)\n",
        "  ax.legend()\n",
        "  ax.grid(False)\n",
        "\n",
        "  # Second chart\n",
        "  ax = fig.add_subplot(312)\n",
        "  ax.plot(perf['gross_leverage'],label='Exposure',\n",
        "          linestyle='-', linewidth=1.0)\n",
        "  ax.legend()\n",
        "  ax.grid(True)\n",
        "  \n",
        "  # Third chart\n",
        "  ax = fig.add_subplot(313)\n",
        "  ax.plot(perf['returns'], label='Returns', linestyle='-.',\n",
        "          linewidth=1.0)\n",
        "  ax.legend()\n",
        "  ax.grid(True)\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "# Set start and end date\n",
        "start_date = pd.Timestamp('2016-05-02', tz='utc')\n",
        "end_date = pd.Timestamp('2020-05-02', tz='utc')\n",
        "\n",
        "# Fire off the backtest\n",
        "perf = run_algorithm(\n",
        "start=start_date,\n",
        "end=end_date,\n",
        "initialize=initialize,\n",
        "analyze=analyze,\n",
        "handle_data=handle_data,\n",
        "capital_base=10000,\n",
        "data_frequency = 'daily', \n",
        "bundle= 'crypto',)"
      ],
      "metadata": {
        "id": "JEtmR8GjFANc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Export performance results to disk in csv file\n",
        "\n",
        "perf.portfolio_value.to_csv('ewm_momentum_model.csv')"
      ],
      "metadata": {
        "id": "BU2OOl30YXe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Momentum Model"
      ],
      "metadata": {
        "id": "1V0GCt2_92BD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import zipline\n",
        "from zipline import run_algorithm\n",
        "from zipline.api import order_target_percent, symbol, set_commission, set_slippage, schedule_function, date_rules, time_rules\n",
        "import matplotlib.pyplot as plt \n",
        "import pyfolio as pf\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from zipline.finance.commission import PerDollar\n",
        "from zipline.finance.slippage import VolumeShareSlippage, FixedSlippage\n",
        "\n",
        "\n",
        "initial_portfolio = 10000\n",
        "minimum_momentum = 10\n",
        "portfolio_size = 1\n",
        "vola_window = 30\n",
        "\n",
        "def momentum_score(ts):\n",
        "\n",
        "  #Input: Price time series.Output: Annualized exponential regression slope, multiplied by the R2\n",
        "\n",
        "  # Make a list of consecutive numbers \n",
        "  x = np.arange(len(ts))\n",
        "  # Get logs\n",
        "  log_ts = np.log(ts)\n",
        "  # Calculate regression values\n",
        "  slope, intercept, r_value, p_value, std_err = stats.linregress(x, log_ts) \n",
        "  # Annualize percent\n",
        "  annualized_slope = (np.power(np.exp(slope), 252) - 1) * 100 \n",
        "  #Adjust for fitness\n",
        "  score = annualized_slope * (r_value ** 2) \n",
        "  return score\n",
        "\n",
        "def volatility(ts):\n",
        "  return ts.pct_change().rolling(vola_window).std().iloc[-1]\n",
        "\n",
        "\n",
        "#Initialization and trading logic\n",
        "\n",
        "\n",
        "def initialize(context):\n",
        "\n",
        "  context.rolling_window = 100\n",
        "\n",
        "  #Commission and Slippage Settings\n",
        "\n",
        "  enable_commission = True \n",
        "  commission_pct = 0.001 \n",
        "  enable_slippage = True \n",
        "  slippage_volume_limit = 0.025\n",
        "  slippage_impact = 0.05\n",
        "\n",
        "  \"\"\"\n",
        "  dji = [\"AAVE\",\"ADA\",\"ALPHA\",\"BCH\",\"BTC\",\n",
        "          \"DOGE\",\"DOT\",\"ETH\",\"LTC\",\"USDT\",\n",
        "          \"XLM\",\"XMR\",\"XRP\"]\n",
        "  \"\"\"\n",
        "  dji = [\"btc\",\"ltc\",\"eth\"]\n",
        "\n",
        "  \n",
        "  # Make a list of symbols from the list of tickers\n",
        "  context.dji_symbols = [symbol(s) for s in dji]\n",
        "\n",
        "  # Set commission and slippage.\n",
        "  if enable_commission:\n",
        "    comm_model = PerDollar(cost=commission_pct) \n",
        "  else:\n",
        "    comm_model = PerDollar(cost=0.0) \n",
        "  set_commission(comm_model)\n",
        "  if enable_slippage: slippage_model=VolumeShareSlippage(volume_limit=slippage_volume_limit,\n",
        "price_impact=slippage_impact) \n",
        "  else:\n",
        "    slippage_model=FixedSlippage(spread=0.0) \n",
        "  set_slippage(slippage_model)\n",
        "\n",
        "\n",
        "  #Schedule rebalance monthly. \n",
        "  schedule_function(\n",
        "    func=rebalance, \n",
        "    date_rule=date_rules.month_start(), \n",
        "    time_rule=time_rules.market_open()\n",
        "  )\n",
        "\n",
        "def rebalance(context, data):\n",
        "\n",
        "  # Get historical data\n",
        "  hist = data.history(context.dji_symbols, \"close\", context.rolling_window, \"1d\")\n",
        "\n",
        "  # Make momentum ranking table\n",
        "  ranking_table = hist.apply(momentum_score).sort_values(ascending=False)\n",
        "\n",
        "  #Sell Logic\n",
        "  #First we check if any existing position should be sold.\n",
        "    #Sell if stock is no longer part of index.\n",
        "    #Sell if stock has too low momentum value.\n",
        "\n",
        "  kept_positions = list(context.portfolio.positions.keys()) \n",
        "  for security in context.portfolio.positions:\n",
        "    if ranking_table[security] < minimum_momentum: \n",
        "      order_target_percent(security, 0.0)\n",
        "      kept_positions.remove(security)\n",
        " \n",
        "  #Stock Selection Logic\n",
        "  #Check how many stocks we are keeping from last month.\n",
        "  #Fill from top of ranking list, until we reach the desired total number of portfolio holdings.\n",
        "\n",
        "  replacement_stocks = portfolio_size - len(kept_positions) \n",
        "  buy_list = ranking_table.loc[\n",
        "    ~ranking_table.index.isin(kept_positions)][:replacement_stocks]\n",
        "  new_portfolio = pd.concat(\n",
        "    (buy_list,\n",
        "    ranking_table.loc[ranking_table.index.isin(kept_positions)])\n",
        "  )\n",
        "  buy_list = ranking_table.loc[\n",
        "    ~ranking_table.index.isin(kept_positions)][:replacement_stocks]\n",
        "\n",
        "  #Calculate inverse volatility for stocks, and make target position weights.\n",
        "\n",
        "  vola_table = hist[new_portfolio.index].apply(volatility) \n",
        "  inv_vola_table = 1 / vola_table\n",
        "  sum_inv_vola = np.sum(inv_vola_table) \n",
        "  vola_target_weights = inv_vola_table / sum_inv_vola\n",
        "  for security, rank in new_portfolio.iteritems(): \n",
        "    weight = vola_target_weights[security]\n",
        "    if security in kept_positions:\n",
        "      order_target_percent(security, weight)\n",
        "    else:\n",
        "      if ranking_table[security] > minimum_momentum: \n",
        "        order_target_percent(security, weight)\n",
        "\n",
        "\n",
        "def analyze(context, perf):\n",
        "    \n",
        "  # Use PyFolio to generate a performance report\n",
        "  returns, positions, transactions = pf.utils.extract_rets_pos_txn_from_zipline(perf)\n",
        "\n",
        "  benchmark_period_return = perf['benchmark_period_return']\n",
        "\n",
        "  daily_benchmark_returns = np.exp(np.log(benchmark_period_return + 1.0).diff()) - 1\n",
        "\n",
        "  # Create tear sheet\n",
        "  pf.create_full_tear_sheet(returns, positions=positions, transactions=transactions, benchmark_rets=None)\n",
        "\n",
        "start= pd.Timestamp('2015-5-1', tz='utc')\n",
        "end = pd.Timestamp('2022-5-2', tz='utc')\n",
        "\n",
        "perf = zipline.run_algorithm(start=start, \n",
        "                             end=end, \n",
        "                             initialize=initialize, \n",
        "                             analyze=analyze, \n",
        "                             capital_base=initial_portfolio, \n",
        "                             data_frequency='daily',\n",
        "                             bundle='crypto')"
      ],
      "metadata": {
        "id": "OfmZYBZ4p4nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Export Performance Result to disk in csv file\n",
        "\n",
        "perf.portfolio_value.to_csv('crypto_momentum.csv')"
      ],
      "metadata": {
        "id": "M18L5KZe3rQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Performance**"
      ],
      "metadata": {
        "id": "kPK0-JU_Y1Ke"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gyaPFiaykaNm",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA CLEANING**\n",
        "\n"
      ],
      "metadata": {
        "id": "wOl0psqAtAal"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Futures"
      ],
      "metadata": {
        "id": "leJ4xVj0cUmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import modules\n",
        "import nasdaqdatalink\n",
        "import quandl\n",
        "# Get the data for Futures, Continuous Contract #6.\n",
        "import matplotlib.pyplot as plt\n",
        "data = quandl.get(\"CHRIS/CME_YM1\",start_date=\"2017-12-03\", end_date=\"2018-12-03\", api_key='WDDHaLh3eG6vrEgiCCqy')"
      ],
      "metadata": {
        "id": "RC5tgJ5vmc7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the prices\n",
        "data.Settle.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "84lZG881mitG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import required libraries\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "\n",
        "data = data.rename(columns={'Open': 'open','High':'high',\n",
        "                                'Low':'low','Last':'close',\n",
        "                                'Volume':'volume','Previous Day Open Interest': 'openinterest'}, index=None)\n",
        "\n",
        "data['expiration_date'] = '2018-12-21'\n",
        "data['root_symbol'] = 'YM'\n",
        "data['symbol'] = 'YMZ18'\n",
        "\n",
        "new_data = data.drop(['Change', 'Settle',], axis=1)\n",
        "\n",
        "print(new_data.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "6aDFt_ctctAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data.to_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/Futures/YMZ18.csv')"
      ],
      "metadata": {
        "id": "U-luxklmprlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Digital assets"
      ],
      "metadata": {
        "id": "j9Isr0HFaAKD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adjusting model performace csv data for comparison"
      ],
      "metadata": {
        "id": "xkG3Yi2EHM4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "A = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/Backtests/Raw Model Performance Data/Digital Assets/crypto_momentum.csv', parse_dates=True, index_col=0)\n",
        "\n",
        "A.index = A.index.strftime('%Y/%m/%d')\n",
        "\n",
        "header_row = 1\n",
        "\n",
        "A.columns = A.iloc[header_row]\n",
        "\n",
        "A"
      ],
      "metadata": {
        "id": "HkR-LQr5HUfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A.info()"
      ],
      "metadata": {
        "id": "dwSpgXWbjPHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "A.to_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/Backtests/crypto_momentum_2.csv')\n"
      ],
      "metadata": {
        "id": "zpol9KKPOz0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adjusting crypto indices csv data for comparison"
      ],
      "metadata": {
        "id": "xcAQevGKs8jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import required libraries\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import exchange_calendars as xcals\n",
        "from zipline import get_calendar\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/indices/SPCBDM.csv', encoding='cp1252')\n",
        "df.info()\n",
        "print(df)"
      ],
      "metadata": {
        "id": "Ui2xKWSwvQsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.drop([1355],axis=0, inplace = True )\n",
        "\n",
        "#Convert 'date' Column to datetime\n",
        "df['2/28/2017'] = pd.to_datetime(df['2/28/2017'], utc=True)\n",
        "\n",
        "#Set 'date' column as index\n",
        "df.set_index('2/28/2017', inplace=True)\n",
        "\n",
        "# Get all expected trading sessions in new dataframe.\n",
        "sessions = get_calendar('NYSE').sessions_in_range('2017-02-28', '2022-05-05')\n",
        "\n",
        "df.index = df.index.strftime('%Y/%m/%d')\n",
        "\n",
        "header_row = 1\n",
        "\n",
        "df.columns = df.iloc[header_row]\n",
        "\n",
        "df.tail(5)\n",
        "df.info()\n",
        "df"
      ],
      "metadata": {
        "id": "ccCas1-YyplH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[~df.index.duplicated()]\n",
        "df"
      ],
      "metadata": {
        "id": "6_L-MWp3pbMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/Backtests/SPCBDM_test3.csv')"
      ],
      "metadata": {
        "id": "YxGN_p0ckuRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Removing weekends from timeseries"
      ],
      "metadata": {
        "id": "wyel-4htJj0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "#Import statements\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "\n",
        "#Load csv file from disc\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/crypto_data/DOGE.csv')\n",
        "\n",
        "#Set date column to datetime\n",
        "df['time'] = pd.to_datetime(df['time'], errors='coerce')\n",
        "\n",
        "#Remove weekends from data\n",
        "df = df[df.time.dt.weekday < 5]\n",
        "\n",
        "#Set 'date' columns as Index\n",
        "df.set_index(\"time\", inplace = True)\n",
        "\n",
        "#display weekday dataframe\n",
        "df"
      ],
      "metadata": {
        "id": "LcR4uk8SJ3mT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#inspect dataframe\n",
        "df.info()"
      ],
      "metadata": {
        "id": "b2HfyHCXUYBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save dataframe to csv\n",
        "\n",
        "df.to_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/crypto weekday data/DODGE_weekday.csv')"
      ],
      "metadata": {
        "id": "t91Kk-vQRL8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load final data to file to dataframe\n",
        "dodge = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/crypto weekday data/DODGE_weekday.csv')\n",
        "\n",
        "print(dodge)\n",
        "\n"
      ],
      "metadata": {
        "id": "biKqcgmYUzrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove weekends from dataframe\n",
        "btc = usholidays[usholidays.date.dt.weekday < 5]\n",
        "\n",
        "#Set 'date' column as index\n",
        "btc.set_index('date', inplace = True)\n",
        "\n",
        "btc"
      ],
      "metadata": {
        "id": "z2i2hsa_DPOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import US holiday calender\n",
        "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
        "\n",
        "#Set period between start and end date in dataframe to identify and remove holidays\n",
        "holidays = calendar().holidays(start='2009-01-05', end='2022-05-24') \n",
        "m = raw_data['date'].isin(holidays)\n",
        "usholidays = raw_data[~m].copy()\n",
        "\n",
        "#print new dataframe with holidays removed\n",
        "usholidays"
      ],
      "metadata": {
        "id": "CBI8-xSAAoRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adjusting crypto data from **Yahoo Finance** for testing with NYSE trading calender."
      ],
      "metadata": {
        "id": "apiTpYe_fJXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import required libraries\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import exchange_calendars as xcals\n",
        "from zipline import get_calendar\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "62ohBdKTfmjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/yahoo_data/yahoo raw data/BTC-USD.csv', parse_dates=True, index_col=0)\n",
        "\n",
        "# Remove Adj Close Column\n",
        "new_df = df.drop(['Adj Close'], axis=1)\n",
        "\n",
        "new_df[\"Volume\"] = new_df[\"Volume\"].astype(float)\n",
        "\n",
        "#Reset index\n",
        "new_df.reset_index(inplace = True)\n",
        "\n",
        "#Convert 'date' Column to datetime\n",
        "new_df['Date'] = pd.to_datetime(new_df['Date'], utc=True)\n",
        "\n",
        "#Set 'date' column as index\n",
        "new_df.set_index('Date', inplace=True)\n",
        "\n",
        "# Get all expected trading sessions in new dataframe.\n",
        "sessions = get_calendar('NYSE').sessions_in_range('2009-01-05', '2022-07-07')\n",
        "\n",
        "# To set the trading session in  new dataframe to the NYSE Calender\n",
        "btc = new_df.reindex(sessions)\n",
        "\n",
        "#Reset index again to change the index name\n",
        "btc.reset_index(inplace = True)\n",
        "\n",
        "#Rename index column to 'date'\n",
        "btc = btc.rename(columns={'index': 'trading_date'}, index=None)\n",
        "\n",
        "#Change date format to Year-Month-Day\n",
        "btc['trading_date'] =  pd.to_datetime(btc['trading_date']).dt.strftime('%Y-%m-%d')\n",
        "\n",
        "crypto = btc.dropna()\n",
        "\n",
        "#Change 'PriceUSD' columns to 'close'\n",
        "crypto.rename(columns = {'Open':'open',\n",
        "                      'High':'high',\n",
        "                      'Low':'low',\n",
        "                      'Close':'close',\n",
        "                      'Volume':'volume'}, inplace = True)\n",
        "\n",
        "crypto.set_index('trading_date', inplace=True)\n",
        "\n",
        "crypto.info()\n",
        "\n",
        "crypto.to_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/yahoo_data/yahoo cleaned data/btc.csv')\n",
        "\n",
        "crypto"
      ],
      "metadata": {
        "id": "9Zw_h3y8fQBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adjusting crypto data from **Coinmetrics** for testing with NYSE trading calender."
      ],
      "metadata": {
        "id": "ZoZBFEZFb1JM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import required libraries\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import exchange_calendars as xcals\n",
        "from zipline import get_calendar\n",
        "import numpy as np\n",
        "\n",
        "#load raw data from file\n",
        "raw_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/coinmetrics_data/btc.csv', parse_dates=True, index_col=0)\n",
        "\n",
        "new = raw_data.drop(raw_data.loc[:, :'PriceBTC'].columns, axis=1)\n",
        "\n",
        "\n",
        "#drop columns not needed. Only closing prices required\n",
        "new.drop(new.iloc[:, 1:76], inplace = True, axis = 1)\n",
        "\n",
        "#Add new columns\n",
        "new['high'] =0\n",
        "new['low'] =0\n",
        "new['open'] =0\n",
        "new['volume'] =0\n",
        "\n",
        "# Rearrange columns to set timestamp as first column\n",
        "new = new[['high','open','low','PriceUSD','volume']]\n",
        "\n",
        "#Change 'PriceUSD' columns to 'close'\n",
        "new.rename(columns = {'PriceUSD':'close'}, inplace = True)\n",
        "\n",
        "\"\"\"\n",
        "#Drop row (date) not needed\n",
        "new=new.drop(['2022-05-25'])\n",
        "\"\"\"\n",
        "\n",
        "#Fill 'close' column with integer values '0'\n",
        "new[\"close\"].fillna(0, inplace=True)\n",
        "\n",
        "#Reset index\n",
        "new.reset_index(inplace = True)\n",
        "\n",
        "#Rename time columns to date\n",
        "new = new.rename(columns={'time': 'date'}, index=None)\n",
        "\n",
        "#Drop all NaN values from dataframe\n",
        "new.dropna()\n",
        "\n",
        "#Convert columns datatype from integer to float\n",
        "new[\"high\"] = new[\"high\"].astype(float)\n",
        "new[\"open\"] = new[\"open\"].astype(float)\n",
        "new[\"low\"] = new[\"low\"].astype(float)\n",
        "new[\"volume\"] = new[\"volume\"].astype(float)\n",
        "\n",
        "#Convert 'date' Column to datetime\n",
        "new['date'] = pd.to_datetime(new['date'], utc=True)\n",
        "\n",
        "#Set 'date' column as index\n",
        "new.set_index('date', inplace=True)\n",
        "\n",
        "# Get all expected trading sessions in new dataframe.\n",
        "sessions = get_calendar('NYSE').sessions_in_range('2009-01-05', '2022-05-24')\n",
        "\n",
        "# To set the trading session in  new dataframe to the NYSE Calender\n",
        "btc = new.reindex(sessions)\n",
        "\n",
        "#Reset index again to change the index name\n",
        "btc.reset_index(inplace = True)\n",
        "\n",
        "#Rename index column to 'date'\n",
        "btc = btc.rename(columns={'index': 'date'}, index=None)\n",
        "\n",
        "#Change date format to Year-Month-Day\n",
        "btc['date'] =  pd.to_datetime(btc['date']).dt.strftime('%Y-%m-%d')\n",
        "\n",
        "\"\"\"\n",
        "btc.set_index('date', inplace=True)\n",
        "\"\"\"\n",
        "\n",
        "# Remove two columns name is 'C' and 'D'\n",
        "df = btc.drop(['high', 'open','low'], axis=1)\n",
        "\n",
        "df['open'] = df['close'] - (0 * df ['close'])\n",
        "df['high'] = df['open'] - (0 * df ['open'])\n",
        "df['low'] = df['high'] - (0 * df ['high'])\n",
        "\n",
        "# Rearrange columns\n",
        "df = df[['date','open','high','low','close','volume']]\n",
        "\n",
        "df.set_index('date', inplace=True)\n",
        "\n",
        "crypto = df.dropna()\n",
        "\n",
        "crypto.to_csv('/content/drive/MyDrive/Colab Notebooks/My Project Folder/crypto/final crypto bundle/btc.csv')"
      ],
      "metadata": {
        "id": "UQOZCRgetfon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gDZuhdt9s2dd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Exploratory Data Analyses (EDA)**"
      ],
      "metadata": {
        "id": "OlM6TGBPVSmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mpld3"
      ],
      "metadata": {
        "id": "s14iuKoDf7rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\"\"\"\n",
        "import mpld3\n",
        "mpld3.enable_notebook()\n",
        "\"\"\"\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.max_rows', 2)"
      ],
      "metadata": {
        "id": "i5waJ-BLVR5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "File = pd.read_csv('/content/Stocks_final/ABG.JO.csv', parse_dates=True, index_col=0)\n",
        "\n",
        "File.info()\n",
        "\n",
        "print(File.head(5))"
      ],
      "metadata": {
        "id": "7TIUEc7qhsCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "File.describe()"
      ],
      "metadata": {
        "id": "-ACTvJDKWq-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "File['open'].plot(figsize=(12,6), \n",
        "                  linestyle='--',color='black',\n",
        "                  legend='Open')\n",
        "\n",
        "File['high'].plot(figsize=(12,6),\n",
        "                   linestyle='-',color='red',\n",
        "                   legend='High')\n",
        "\n",
        "File['low'].plot(figsize=(12,6),\n",
        "                 linestyle=':',color='blue',\n",
        "                 legend='Low')\n",
        "\"\"\"\n",
        "File['close'].plot(figsize=(12,6),\n",
        "                  linestyle='-',color='red',\n",
        "                  legend='Close')"
      ],
      "metadata": {
        "id": "aPN9i9h3Ydbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_outlier_prices = File[(np.abs(stats.zscore(File)) <\n",
        "6).all(axis=1)]"
      ],
      "metadata": {
        "id": "yGFt1GskpsGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_outlier_prices['low'].plot(figsize=(12,6), linestyle='--',\n",
        "color='black', legend='Low')"
      ],
      "metadata": {
        "id": "kSie4BpYqa8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "no_outlier_prices[['533.95']].describe()"
      ],
      "metadata": {
        "id": "_7kJ7-_Mw1pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DOWNLOAD JSE STOCK PRICES USING MARKETSTACK AND YFINANCE**"
      ],
      "metadata": {
        "id": "pkft-F-8W1im"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install packages**"
      ],
      "metadata": {
        "id": "oOqMYPtEBnw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance"
      ],
      "metadata": {
        "id": "IECOpw6H-TQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yahooquery"
      ],
      "metadata": {
        "id": "iAeOLNoS-X0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run programme**"
      ],
      "metadata": {
        "id": "MY58T5eLBt0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import required libraries\n",
        "import pandas as pd\n",
        "import json\n",
        "import requests\n",
        "from yahooquery import Ticker\n",
        "from datetime import datetime\n",
        "params = {'access_key': 'e52cf3b93696352e880916f8c8adbf0c',\n",
        "          'limit': 350}\n",
        "api_result = requests.get('http://api.marketstack.com/v1/exchanges/XJSE/tickers', params)\n",
        "api_response = api_result.json()\n",
        "print(f\"Exchange Name = {api_response['data']['name']}\")\n",
        "for ticker in api_response['data']['tickers']:\n",
        "  print(f\"{ticker['name']}: {ticker['symbol']}\")\n",
        "\n",
        "\n",
        "# Serializing json\n",
        "json_object = json.dumps(api_response, indent=4)\n",
        "# Writing to sample.json\n",
        "with open(\"jse.json\", \"w\") as outfile:\n",
        "    outfile.write(json_object)\n",
        "# Opening JSON file\n",
        "with open('jse.json', 'r') as openfile:\n",
        "    # Reading from json file\n",
        "    json_object = json.load(openfile)\n",
        "df1 = pd.json_normalize(json_object[\"data\"][\"tickers\"])\n",
        "\n",
        "# dropping null value columns to avoid errors\n",
        "# new data frame with split value columns\n",
        "new = df1[\"symbol\"].str.split(\".\", n = 1, expand = True)\n",
        "# making separate first name column from new data frame\n",
        "df1[\"ticker\"]= new[0]\n",
        "# Dropping old Name columns\n",
        "df1.drop(columns =[\"has_intraday\",\"has_eod\"], inplace = True)\n",
        "new.columns = new.columns.astype(str)\n",
        "new.columns.values[1] = \"tickers\"\n",
        "new['0'] + '.' + new['tickers']\n",
        "new.replace(\"XJSE\", \"JO\", inplace=True)\n",
        "\n",
        "result = pd.concat([df1, new], axis=1, join='inner')\n",
        "df2=result['0'] + '.' + result['tickers']\n",
        "final = pd.concat([df1, df2], axis=1, join='inner')\n",
        "final.columns.values[3] = \"tickers\"\n",
        "final.columns = final.columns.astype(str)\n",
        "#Dropping old Name columns\n",
        "final.drop(columns =[\"name\", \"symbol\",\"ticker\"], inplace = True)\n",
        "# Converting a specific Dataframe \n",
        "# column to list using Series.tolist()\n",
        "xjse = final[\"tickers\"].tolist()  \n",
        "print(\"Converting tickers to list...\")\n",
        "print(\"Output dataframe...\" )\n",
        "print(\"Writing csv file...\" )\n",
        "print(\"Saving JSE data to disc...\")\n",
        "print(\"Saving csv files for each stock to disc...\")  \n",
        "symbols = xjse\n",
        "tickers = Ticker(symbols, asynchronous=True)\n",
        "data = tickers.history(start='1998-01-01', end='2023-04-22', interval='1d')\n",
        "data= data.drop(['adjclose','dividends','splits'],axis=1)\n",
        "\n",
        "\n",
        "#Convert dataframe to csv and save to disc\n",
        "final.to_csv(\"tickers.csv\")\n",
        "data.to_csv(\"jse_stocks.csv\")\n",
        "\n",
        "resetindex = data.reset_index(inplace = True) \n",
        "\n",
        "for i, g in data.groupby('symbol'):\n",
        "    g.to_csv('/content/Stocks/{}.csv'.format(i), header=True, index_label=False)"
      ],
      "metadata": {
        "id": "DCM0ZmyKXD-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SLM = pd.read_csv('/content/Stocks/SLM.JO.csv')\n",
        "\n",
        "# new dataframe with different column order\n",
        "df_new = SLM.iloc[:, [1, 2, 3, 4, 5, 6, 0]]\n",
        "\n",
        "#Change date format to Year-Month-Day\n",
        "df_new['date'] =  pd.to_datetime(df_new['date']).dt.strftime('%Y-%m-%d')\n",
        "\n",
        "df_new.set_index('date', inplace=True)\n",
        "\n",
        "df_new.head(5)\n",
        "df_new.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoXWMlWQOb2W",
        "outputId": "5ff4a230-7e75-4af2-be39-9b403764f77d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 5976 entries, 2000-01-17 to 2023-04-21\n",
            "Data columns (total 6 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   open    5976 non-null   float64\n",
            " 1   high    5976 non-null   float64\n",
            " 2   low     5976 non-null   float64\n",
            " 3   close   5976 non-null   float64\n",
            " 4   volume  5976 non-null   float64\n",
            " 5   symbol  5976 non-null   object \n",
            "dtypes: float64(5), object(1)\n",
            "memory usage: 326.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# importing libraries\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "  \n",
        "# merging the files\n",
        "joined_files = os.path.join(\"/content/Stocks/\", \"*.csv\")\n",
        "  \n",
        "# A list of all joined files is returned\n",
        "joined_list = glob.glob(joined_files)\n",
        "  \n",
        "# Finally, the files are joined\n",
        "df = pd.concat(map(pd.read_csv, joined_list), ignore_index=True)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "99JrppOxAtDb",
        "outputId": "ec56cb7b-7a63-43d2-f2cb-06da5ac3bc47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         symbol                       date    open    high     low   close  \\\n",
            "0        NVS.JO  2015-03-31 02:00:00+02:00  2500.0  2500.0  1600.0  1680.0   \n",
            "1        NVS.JO  2015-04-01 02:00:00+02:00  1850.0  1870.0  1640.0  1650.0   \n",
            "2        NVS.JO  2015-04-02 02:00:00+02:00  1698.0  1800.0  1675.0  1680.0   \n",
            "3        NVS.JO  2015-04-03 02:00:00+02:00  1680.0  1680.0  1680.0  1680.0   \n",
            "4        NVS.JO  2015-04-06 02:00:00+02:00  1680.0  1680.0  1680.0  1680.0   \n",
            "...         ...                        ...     ...     ...     ...     ...   \n",
            "1177264  CRP.JO  2023-04-14 02:00:00+02:00  1246.0  1246.0  1246.0  1246.0   \n",
            "1177265  CRP.JO  2023-04-17 02:00:00+02:00  1246.0  1246.0  1246.0  1246.0   \n",
            "1177266  CRP.JO  2023-04-18 02:00:00+02:00  1246.0  1246.0  1246.0  1246.0   \n",
            "1177267  CRP.JO  2023-04-19 02:00:00+02:00  1246.0  1246.0  1246.0  1246.0   \n",
            "1177268  CRP.JO  2023-04-20 02:00:00+02:00  1246.0  1246.0  1246.0  1246.0   \n",
            "\n",
            "           volume  \n",
            "0        314360.0  \n",
            "1        460918.0  \n",
            "2        154024.0  \n",
            "3             0.0  \n",
            "4             0.0  \n",
            "...           ...  \n",
            "1177264       0.0  \n",
            "1177265       0.0  \n",
            "1177266       0.0  \n",
            "1177267       0.0  \n",
            "1177268       0.0  \n",
            "\n",
            "[1177269 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# new dataframe with different column order\n",
        "df_new2 = df.iloc[:, [1, 2, 3, 4, 5, 6, 0]]\n",
        "\n",
        "#Change date format to Year-Month-Day\n",
        "df_new2['date'] =  pd.to_datetime(df_new2['date']).dt.strftime('%Y-%m-%d')\n",
        "\n",
        "df_new2.set_index('date', inplace=True)\n",
        "\n",
        "df_new2.head(5)\n",
        "df_new2.info()"
      ],
      "metadata": {
        "id": "0Wbwv1YGFv0n",
        "outputId": "5789d735-7166-4182-f4e0-c043056e18d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 1177269 entries, 2015-03-31 to 2023-04-20\n",
            "Data columns (total 6 columns):\n",
            " #   Column  Non-Null Count    Dtype  \n",
            "---  ------  --------------    -----  \n",
            " 0   open    1177268 non-null  float64\n",
            " 1   high    1177268 non-null  float64\n",
            " 2   low     1177268 non-null  float64\n",
            " 3   close   1177268 non-null  float64\n",
            " 4   volume  1177268 non-null  float64\n",
            " 5   symbol  1177269 non-null  object \n",
            "dtypes: float64(5), object(1)\n",
            "memory usage: 62.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#resetindex = df_new2.reset_index(inplace = True) \n",
        "\n",
        "for i, g in df_new2.groupby('symbol'):\n",
        "    g.to_csv('/content/Stocks_final/{}.csv'.format(i), header=True, index_label=False)"
      ],
      "metadata": {
        "id": "txkQl5pYGpmV"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SLM = pd.read_csv('/content/Stocks_final/SLM.JO.csv', parse_dates=True)"
      ],
      "metadata": {
        "id": "il2DZpeDHTdp"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SLM.info()\n",
        "SLM"
      ],
      "metadata": {
        "id": "KSODj2_xHYnv",
        "outputId": "be7a64eb-c7f6-4b9e-e383-f7ae2d1879c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 5976 entries, 2000-01-17 to 2023-04-21\n",
            "Data columns (total 6 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   open    5976 non-null   float64\n",
            " 1   high    5976 non-null   float64\n",
            " 2   low     5976 non-null   float64\n",
            " 3   close   5976 non-null   float64\n",
            " 4   volume  5976 non-null   float64\n",
            " 5   symbol  5976 non-null   object \n",
            "dtypes: float64(5), object(1)\n",
            "memory usage: 326.8+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              open    high     low   close      volume  symbol\n",
              "2000-01-17   980.0   995.0   959.0   977.0   6503053.0  SLM.JO\n",
              "2000-01-18   980.0  1000.0   960.0   978.0  10431653.0  SLM.JO\n",
              "2000-01-19   970.0   975.0   940.0   955.0   2108933.0  SLM.JO\n",
              "2000-01-20   955.0  1020.0   955.0   993.0  10787166.0  SLM.JO\n",
              "2000-01-21   985.0   990.0   965.0   980.0   4339661.0  SLM.JO\n",
              "...            ...     ...     ...     ...         ...     ...\n",
              "2023-04-17  5600.0  5681.0  5558.0  5606.0   4600726.0  SLM.JO\n",
              "2023-04-18  5650.0  5649.0  5575.0  5615.0   4231146.0  SLM.JO\n",
              "2023-04-19  5575.0  5690.0  5528.0  5670.0   3800703.0  SLM.JO\n",
              "2023-04-20  5690.0  5712.0  5588.0  5645.0   4664703.0  SLM.JO\n",
              "2023-04-21  5590.0  5654.0  5490.0  5568.0   4096169.0  SLM.JO\n",
              "\n",
              "[5976 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e21d0163-8721-4b55-a4ce-b1384e38c9ca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>symbol</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-01-17</th>\n",
              "      <td>980.0</td>\n",
              "      <td>995.0</td>\n",
              "      <td>959.0</td>\n",
              "      <td>977.0</td>\n",
              "      <td>6503053.0</td>\n",
              "      <td>SLM.JO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-18</th>\n",
              "      <td>980.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>960.0</td>\n",
              "      <td>978.0</td>\n",
              "      <td>10431653.0</td>\n",
              "      <td>SLM.JO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-19</th>\n",
              "      <td>970.0</td>\n",
              "      <td>975.0</td>\n",
              "      <td>940.0</td>\n",
              "      <td>955.0</td>\n",
              "      <td>2108933.0</td>\n",
              "      <td>SLM.JO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-20</th>\n",
              "      <td>955.0</td>\n",
              "      <td>1020.0</td>\n",
              "      <td>955.0</td>\n",
              "      <td>993.0</td>\n",
              "      <td>10787166.0</td>\n",
              "      <td>SLM.JO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-21</th>\n",
              "      <td>985.0</td>\n",
              "      <td>990.0</td>\n",
              "      <td>965.0</td>\n",
              "      <td>980.0</td>\n",
              "      <td>4339661.0</td>\n",
              "      <td>SLM.JO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-04-17</th>\n",
              "      <td>5600.0</td>\n",
              "      <td>5681.0</td>\n",
              "      <td>5558.0</td>\n",
              "      <td>5606.0</td>\n",
              "      <td>4600726.0</td>\n",
              "      <td>SLM.JO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-04-18</th>\n",
              "      <td>5650.0</td>\n",
              "      <td>5649.0</td>\n",
              "      <td>5575.0</td>\n",
              "      <td>5615.0</td>\n",
              "      <td>4231146.0</td>\n",
              "      <td>SLM.JO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-04-19</th>\n",
              "      <td>5575.0</td>\n",
              "      <td>5690.0</td>\n",
              "      <td>5528.0</td>\n",
              "      <td>5670.0</td>\n",
              "      <td>3800703.0</td>\n",
              "      <td>SLM.JO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-04-20</th>\n",
              "      <td>5690.0</td>\n",
              "      <td>5712.0</td>\n",
              "      <td>5588.0</td>\n",
              "      <td>5645.0</td>\n",
              "      <td>4664703.0</td>\n",
              "      <td>SLM.JO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-04-21</th>\n",
              "      <td>5590.0</td>\n",
              "      <td>5654.0</td>\n",
              "      <td>5490.0</td>\n",
              "      <td>5568.0</td>\n",
              "      <td>4096169.0</td>\n",
              "      <td>SLM.JO</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5976 rows √ó 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e21d0163-8721-4b55-a4ce-b1384e38c9ca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e21d0163-8721-4b55-a4ce-b1384e38c9ca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e21d0163-8721-4b55-a4ce-b1384e38c9ca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**TEST CODE HERE**"
      ],
      "metadata": {
        "id": "SCo0nvnDo2Y-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "JSE = {} \n",
        "tickers = Stocks\n",
        "for t in tickers:\n",
        "    ticker = yf.Ticker(t)\n",
        "    JSE[t] = ticker.history(period=\"2y\")\n",
        "print(JSE)"
      ],
      "metadata": {
        "id": "iuUFA01m8tzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "from datetime import date, timedelta\n",
        "\n",
        "stock_list = Stocks\n",
        "\n",
        "# Specify start dates and end dates\n",
        "end_date = date.today()\n",
        "start_date = end_date - timedelta(days=252)\n",
        "print('start_date:', start_date)\n",
        "print('end_date:', end_date)\n",
        "\n",
        "start_date_list = [start_date + timedelta(days=7*i) for i in range(5)]\n",
        "print('start_date_list:', start_date_list)\n",
        "end_date_list = [start_date_list[i+1] - timedelta(days=1) for i in range(4)] + [end_date]\n",
        "print('end_date_list:', end_date_list)\n",
        "print('===========================================================')\n",
        "\n",
        "# Use for-loop to extract data\n",
        "df_1min = pd.DataFrame({})\n",
        "for idx in range(5):\n",
        "    data = yf.download(stock_list, \n",
        "                       start=start_date_list[idx].strftime(\"%Y-%m-%d\"), \n",
        "                       end=end_date_list[idx].strftime(\"%Y-%m-%d\"), \n",
        "                       interval = \"1d\")\n",
        "    df_1min = df_1min.append(data)\n",
        "df_1min"
      ],
      "metadata": {
        "id": "k4YpwsvyGX2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "def flatten_nested_json_df(df):\n",
        "    df = df.reset_index()\n",
        "    s = (df.applymap(type) == list).all()\n",
        "    list_columns = s[s].index.tolist()\n",
        "    \n",
        "    s = (df.applymap(type) == dict).all()\n",
        "    dict_columns = s[s].index.tolist()\n",
        "\n",
        "    \n",
        "    while len(list_columns) > 0 or len(dict_columns) > 0:\n",
        "        new_columns = []\n",
        "\n",
        "        for col in dict_columns:\n",
        "            horiz_exploded = pd.json_normalize(df[col]).add_prefix(f'{col}.')\n",
        "            horiz_exploded.index = df.index\n",
        "            df = pd.concat([df, horiz_exploded], axis=1).drop(columns=[col])\n",
        "            new_columns.extend(horiz_exploded.columns) # inplace\n",
        "\n",
        "        for col in list_columns:\n",
        "            #print(f\"exploding: {col}\")\n",
        "            df = df.drop(columns=[col]).join(df[col].explode().to_frame())\n",
        "            new_columns.append(col)\n",
        "\n",
        "        s = (df[new_columns].applymap(type) == list).all()\n",
        "        list_columns = s[s].index.tolist()\n",
        "\n",
        "        s = (df[new_columns].applymap(type) == dict).all()\n",
        "        dict_columns = s[s].index.tolist()\n",
        "    return df"
      ],
      "metadata": {
        "id": "NiKou6h6dOO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jsonString = json.dumps(api_response)  #What you gave is not really a json string but a list\n",
        "jsonstr = json.loads(jsonString)\n",
        "results = pd.json_normalize(jsonstr)\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "outdf = flatten_nested_json_df(df)"
      ],
      "metadata": {
        "id": "hTnW5qza5aiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outdf"
      ],
      "metadata": {
        "id": "NCJmIPMS7mIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "csv_file_list = glob.glob(Dir + '/content/')\n",
        "with open(Avg_Dir + '.csv','w') as wf:\n",
        "    for file in csv_file_list:\n",
        "        with open(file) as rf:\n",
        "            for line in rf:\n",
        "                if line.strip(): # if line is not empty\n",
        "                    if not line.endswith(\"\\n\"):\n",
        "                        line+=\"\\n\"\n",
        "                    wf.write(line)"
      ],
      "metadata": {
        "id": "PnRWrr26Ey9V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}